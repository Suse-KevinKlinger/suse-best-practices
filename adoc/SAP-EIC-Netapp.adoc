
:netapp: NetApp
:trid: Trident


== Installing {trid}

This chapter describes how to install {trid} in a RKE2 cluster using Helm.
For more details how to install {trid} with Helm, visit https://docs.netapp.com/us-en/trident/trident-get-started/kubernetes-deploy-helm.html#critical-information-about-trident-25-02


=== Preparing the OS 

The Kubernetes worker nodes must be prepared so PVCs can later be provisioned properly.
Thus you need to install the following packages:

[source, bash, subs="attributes"]
----
$ zypper in -y lsscsi multipath-tools
----

As multipathd is known to have problems on OS using the kernel-default-base packages, replace them with kernel-default:

[source, bash, subs="attributes"]
----
$ zypper remove -y kernel-default-base && zypper in -y kernel-default
----

Afterwards you can enable iscsi and multipath
[source, bash, subs="attributes"]
----
$ sytemctl enablle --now iscsi
$ sytemctl enablle --now multipathd
----

=== Deploying the {trid} operator

The {trid} operator is responsible to establish the connection between your {netapp} storage system and the Kubernetes cluster.
An example of how to deploy it looks like follows:

[source, bash, subs="attributes"]
----
$ helm repo add netapp-trident https://netapp.github.io/trident-helm-chart
$ helm install my-trident-operator netapp-trident/trident-operator --version 100.2502.1 --create-namespace --namespace trident
----

=== Establish the connection between Kubernetes and the {netapp} storage

Before creating the link to the backend, it's recommended to store the user and password information in a Secret.
To create such a secret you can use:

[source, yaml, subs="attributes"]
----
apiVersion: v1
kind: Secret
metadata:
  name: backend-tbc-ontap-san-secret
  namespace: trident
type: Opaque
stringData:
  username: <cluster-admin>
  password: <password>
----

To establish the connection between the target Kubernetes cluster and the {netapp} storage system, a so called *TridentBackendConfig* is required.
To get more information how to set up the backend configuration, refer to https://docs.netapp.com/us-en/trident/trident-use/backend-kubectl.html#tridentbackendconfig




[source, yaml, subs="attributes"]
----
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: backend-tbc-ontap-san
  namespace: trident
spec:
  version: 1
  backendName: ontap-san-backend
  storageDriverName: ontap-san
  managementLIF: <Cluster IP>
  dataLIF: <Storage-VM-IP>
  svm: <Storage-VM-FQDN>
  credentials:
    name: backend-tbc-ontap-san-secret
----


[source, yaml, subs="attributes"]
----
apiVersion: trident.netapp.io/v1
kind: TridentBackendConfig
metadata:
  name: backend-tbc-ontap-nas
  namespace: trident
spec:
  version: 1
  backendName: ontap-nas-backend
  storageDriverName: ontap-nas
  managementLIF: <Cluster-IP>
  dataLIF: <Storage-VM-IP>
  svm: <Storage-VM-FQDN>
  credentials:
    name: backend-tbc-ontap-san-secret
----

To verify the backend was configured successfuly, check the output of:

[source, bash, subs="attributes"]
----
$ kubectl -n trident get tbc backend-tbc-ontap-san
----

If the connection was established, the *State* should be active and you should see a *Backend UUID*

//TODO example picture

Once the backend is configured, you can create a *StorageClass* to provision Volumes to be consumed by a Perstistent Volume Claim.
Here's an example that will create a storageClass that will use an SAN/iscsi backend:

[source, yaml, subs="attributes"]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs
provisioner: csi.trident.netapp.io
parameters:
  backendType: ontap-san
----
